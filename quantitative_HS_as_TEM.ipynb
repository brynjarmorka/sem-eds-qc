{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperspy.api as hs\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SEM Apreo March 2023 #####\n",
    "path = '../../Masteroppgave/2023-03-08_EDS-Apreo/exports/'\n",
    "aztec_TEM_file = '../../Masteroppgave/2023-03-08_EDS-Apreo/AZtec quant as EDS_TEM.xlsx'\n",
    "df = pd.read_excel(aztec_TEM_file, sheet_name=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_as_TEM(filename, a_corr=True, noise_slice=0.65, print_results=False):\n",
    "\n",
    "    # thickness_list = [1e2, 1e3,1e4,1e5] # in nm\n",
    "    thickness_list = [50, 100, 200, 400, 1e3, 1e4, 1e5] # in nm\n",
    "\n",
    "    if filename + '.emsa' not in os.listdir(path):\n",
    "        print(filename + '.emsa', 'not found in path')\n",
    "        return\n",
    "    \n",
    "    df_s = df[df['File'] == filename]\n",
    "    df_s = df_s.sort_values(by=['Element']) # alphabetically, as HS\n",
    "\n",
    "    # make the spectrum and the model\n",
    "    s = hs.load(path + filename + '.emsa', signal_type='EDS_TEM')\n",
    "    elements = df_s['Element'].values\n",
    "    s = s.isig[noise_slice:] # noise peak slice\n",
    "    # if Vacc is lower than 20, slice at Vacc\n",
    "    if s.metadata.Acquisition_instrument.TEM.beam_energy < 20:\n",
    "        s = s.isig[:s.metadata.Acquisition_instrument.TEM.beam_energy]\n",
    "\n",
    "    s.add_elements(elements)\n",
    "    s.add_lines()\n",
    "    m = s.create_model()\n",
    "    m.fit()\n",
    "    m.fit_background()\n",
    "\n",
    "    lines = df_s['Line'].values\n",
    "    kfactors = df_s['k-factor'].values\n",
    "    intensities = s.get_lines_intensity()\n",
    "    m_intensities = m.get_lines_intensity()\n",
    "\n",
    "    # select only the relevant lines in m (relevant = we have a k-factor for it from AZtec)    \n",
    "    lines_in_m_to_use = []\n",
    "    for m_line in m_intensities:\n",
    "        if m_line.metadata.Sample.xray_lines[0] in lines:\n",
    "            lines_in_m_to_use.append(m_line)\n",
    "    if a_corr:\n",
    "    # calculate %at for each line in m, if possible\n",
    "        for l in lines:\n",
    "            try:\n",
    "                m[l]\n",
    "                for thickness in thickness_list:\n",
    "                    at_m = s.quantification(lines_in_m_to_use, factors=kfactors, method='CL', absorption_correction=True, thickness=thickness)\n",
    "                    df_s[f'HS %at m A t={thickness:.0e}'] = [at_m[0][0].data.round(2)[0], at_m[0][1].data.round(2)[0]]\n",
    "            except:\n",
    "                print(l, 'not found in m, quantification with model not possible')\n",
    "                df_s[f'HS %at m A t={thickness:.0e}'] = [np.nan, np.nan]\n",
    "\n",
    "        # do the CL quantification with the intensities from the original spectrum\n",
    "        at = s.quantification(intensities, factors=kfactors, method='CL', absorption_correction=True, thickness=thickness)\n",
    "        df_s['HS %at s A'] = [at[0][0].data.round(2)[0], at[0][1].data.round(2)[0]]\n",
    "    \n",
    "    else: # no absorption correction\n",
    "        # almost the same code, but slicing at and at_m with one less level\n",
    "        for l in lines:\n",
    "            try:\n",
    "                m[l]\n",
    "                at_m = s.quantification(lines_in_m_to_use, factors=kfactors, method='CL')\n",
    "                df_s['HS %at m'] = [at_m[0].data.round(2)[0], at_m[1].data.round(2)[0]]\n",
    "            except:\n",
    "                print(l, 'not found in m, quantification with model not possible')\n",
    "                df_s['HS %at m'] = [np.nan, np.nan]\n",
    "        at = s.quantification(intensities, factors=kfactors, method='CL')\n",
    "        df_s['HS %at s'] = [at[0].data.round(2)[0], at[1].data.round(2)[0]]\n",
    "            \n",
    "    if print_results:\n",
    "        print(df_s)\n",
    "\n",
    "    # put results back in df\n",
    "    df[df['File'] == filename] = df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "quant_as_TEM('GaAs_30kV_25pA',print_results=True)\n",
    "#\n",
    "quant_as_TEM('GaAs_30kV_25pA',print_results=True, a_corr=False)\n",
    "#\n",
    "quant_as_TEM('GaAs_30kV_25pA',print_results=True)\n",
    "quant_as_TEM('GaAs_30kV_25pA',print_results=True, a_corr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the routine for all files in df\n",
    "# took 3-4 min\n",
    "for f in df['File'].unique():\n",
    "    print(f)\n",
    "    quant_as_TEM(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 30 sec\n",
    "for f in df['File'].unique():\n",
    "    print(f)\n",
    "    quant_as_TEM(f, a_corr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df to excel\n",
    "df.to_excel('results/quant_as_TEM.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "lines_list = ['Sb_La', 'As_Ka', 'Ga_Ka', 'Ga_La', 'As_La']\n",
    "colors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52'] # plotly colors\n",
    "          \n",
    "y_keys = ['AZ %at', 'HS %at s','HS %at m A t=5e+01', 'HS %at m A t=1e+02', 'HS %at m A t=2e+02', 'HS %at m A t=4e+02', 'HS %at m A t=1e+03', 'HS %at m A t=1e+04', 'HS %at m A t=1e+05']\n",
    "\n",
    "for l in lines_list:\n",
    "    for y in y_keys:\n",
    "        i = y_keys.index(y)\n",
    "        fig.add_scatter(x=df[df['Line'] == l]['File'], y = df[df['Line'] == l][y], mode='markers', name=y, marker=dict(size=8, color=colors[i]), legendgroup=y, showlegend=True if l == lines_list[0] else False)\n",
    "fig.update_layout(title='Data treated as TEM, quantified with HS using different quantification parameters<br><sub>s=original spectrum, m=model, A=absorption correction, t=thickness')\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "fig\n",
    "# fig.write_html('results/quant_as_TEM.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
